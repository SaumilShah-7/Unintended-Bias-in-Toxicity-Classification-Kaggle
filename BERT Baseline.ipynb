{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BERT (Unintended Bias).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaumilShah-7/Unintended-Bias-in-Toxicity-Classification-Kaggle/blob/master/BERT%20Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7a1614b1-939e-48bc-823c-279f118fe6d6",
        "_cell_guid": "1a12694e-4944-41a1-aef6-6f97ecd1d67a",
        "trusted": true,
        "id": "3VBnAZ6V6R3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall torch -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "99d45ae7-2a71-4a54-b2ff-792e08470e7f",
        "_cell_guid": "905aa639-35df-4490-b238-7556043ead82",
        "trusted": true,
        "id": "M3tU6pnP6R30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "01701131-81da-4a9a-a82f-44bbbcc8e5ae",
        "_cell_guid": "764fc30f-90fd-40fd-9e60-fb23ef32cdaa",
        "trusted": true,
        "scrolled": true,
        "id": "hUzLJBUJ6R4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "import gc\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9f55cb5e-6c99-4651-badd-6a7fb1388245",
        "_cell_guid": "5b208182-ff72-4dd6-a7b1-8a0249a8ed2a",
        "trusted": true,
        "id": "8x72vrKJ6R40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
        "\n",
        "from apex import amp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8793ea70-8826-4dcc-96c8-a26ed69500c1",
        "_cell_guid": "175cd5a6-a40f-4893-86fd-03ed393cf6d5",
        "trusted": true,
        "scrolled": true,
        "id": "35Pmi0Oy6R5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_package_dir = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
        "sys.path.insert(0, bert_package_dir)\n",
        "\n",
        "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch, BertConfig, BertTokenizer, BertForSequenceClassification, BertAdam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "702c9866-da2f-4f9c-b582-de3eea027e64",
        "_cell_guid": "ddf70e73-62df-4bcd-b9fc-e32241fb8445",
        "trusted": true,
        "id": "ITKVvfat6R5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model_path = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n",
        "\n",
        "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(bert_model_path + 'bert_model.ckpt', bert_model_path + 'bert_config.json', 'pytorch_model.bin')\n",
        "\n",
        "shutil.copyfile(bert_model_path + 'bert_config.json', 'bert_config.json')\n",
        "bert_config = BertConfig(bert_model_path + 'bert_config.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a54ea757-351a-42ae-ac35-0727adf12f91",
        "_cell_guid": "a8a39ddc-03c9-48b5-8618-74c3dd1e0c3c",
        "trusted": true,
        "scrolled": true,
        "id": "YXGZ9LCb6R8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lines(example, max_seq_length, tokenizer):\n",
        "    max_seq_length -= 2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    for text in tqdm(example):\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        if len(tokens) > max_seq_length:\n",
        "            tokens = tokens[:max_seq_length]\n",
        "            longer += 1\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens+[\"[SEP]\"]) + [0]*(max_seq_length - len(tokens))\n",
        "        all_tokens.append(one_token)\n",
        "    print(longer)\n",
        "    return np.array(all_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e709596f-19e3-4e0a-9000-018b43fa7853",
        "_cell_guid": "ee6e278e-00a1-488a-939d-2ef7e6e4b409",
        "trusted": true,
        "scrolled": true,
        "id": "z6dSloIq6R8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "num_to_load = 700000\n",
        "\n",
        "train_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv').sample(num_to_load, random_state=SEED)\n",
        "print(train_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "accb3f98-9bee-4b62-b244-0377ddfd3ea3",
        "_cell_guid": "71c66950-594a-42ff-904e-332a1941033a",
        "trusted": true,
        "id": "fpQHjynX6R9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 220\n",
        "\n",
        "train_df['comment_text'] = train_df['comment_text'].astype(str).fillna('DUMMY_VALUE')\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_path, cache_dir=None, do_lower_case=True)\n",
        "\n",
        "sequences = convert_lines(train_df[\"comment_text\"], max_seq_length, tokenizer)\n",
        "\n",
        "with open('sequences.pickle', 'wb') as handle:\n",
        "  pickle.dump(sequences, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('../input/bert-unintended-bias/sequences.pickle', 'rb') as handle:\n",
        "#     sequences = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6b5474d8-5494-4a06-815d-f9ad230f6ab0",
        "_cell_guid": "02e4ab12-1e39-4724-b12a-d5df464aa4a5",
        "trusted": true,
        "id": "xUXZanha6R9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "y_columns = ['target']\n",
        "\n",
        "train_df = train_df.fillna(0)\n",
        "train_df[y_columns] = (train_df[y_columns]>=0.5).astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3c186461-ec42-4b9b-957e-6cbe261f26a1",
        "_cell_guid": "8b767bbd-8a77-4d55-99d9-7cf92eb1536f",
        "trusted": true,
        "scrolled": true,
        "id": "zae7W1mv6R94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sequences[:num_to_load]                \n",
        "y = train_df[y_columns].values[:num_to_load]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6d4c031d-405c-45d0-94d9-e712235b0520",
        "_cell_guid": "7a227dc7-5364-4014-a7ff-b9ba36eb3e37",
        "trusted": true,
        "id": "jkufen_O6R-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "886ed195-b4b8-4c42-a7cb-8f99b4d30bf9",
        "_cell_guid": "957e4ee0-96a2-4172-9c35-fdfd274adfe9",
        "trusted": true,
        "id": "65dnHVS46R-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "lr = 2e-5\n",
        "batch_size = 32\n",
        "accumulation_steps = 2\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0c2110cc-056c-4c88-9839-d901bb08df0f",
        "_cell_guid": "40d5e7e8-539f-403d-b327-b1f5678eeefc",
        "trusted": true,
        "id": "v57hagFi6R_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d0a0f635-be09-457c-b46b-e44bbca2e000",
        "_cell_guid": "1554ae9f-f0b0-4978-98ef-fd7bc9e94a5a",
        "trusted": true,
        "id": "Nm3R7LYf6R_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"./\", cache_dir=None, num_labels=len(y_columns))\n",
        "\n",
        "model.zero_grad()\n",
        "model = model.to(device)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "num_train_optimization_steps = int(epochs*len(train)/batch_size/accumulation_steps)\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=lr, warmup=0.05, t_total=num_train_optimization_steps)\n",
        "\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "model = model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "eb22bdc9-59c8-444e-9cf9-0834b1b2c242",
        "_cell_guid": "4e140337-1041-4811-be2f-bb151897fa62",
        "trusted": true,
        "id": "F3IHbcGh6SAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint = torch.load('./bert_pytorch_checkpoint.bin')\n",
        "\n",
        "# model = BertForSequenceClassification(bert_config, num_labels=len(y_columns))\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# model.zero_grad()\n",
        "# model = model.to(device)\n",
        "\n",
        "# param_optimizer = list(model.named_parameters())\n",
        "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "# optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "# num_train_optimization_steps = int(epochs*len(train)/batch_size/accumulation_steps)\n",
        "# optimizer = BertAdam(optimizer_grouped_parameters, lr=lr, warmup=0.05, t_total=num_train_optimization_steps)\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "# model = model.eval()\n",
        "\n",
        "# del checkpoint\n",
        "# torch.cuda.empty_cache()\n",
        "# gc.collect()\n",
        "# print(round(torch.cuda.memory_allocated(device)/(1024**3),1), round(torch.cuda.memory_cached(device)/(1024**3),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2f95ff89-5d3a-4d59-b908-18364bec8d35",
        "_cell_guid": "e2092674-9fb0-4f86-971e-1398e91b94a1",
        "trusted": true,
        "id": "lBcNSV1K6SAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tq1 = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "\n",
        "# for i, (x_batch, y_batch) in tq1:\n",
        "#     if i == len(train_loader) / 2:\n",
        "#         x_batch_t = x_batch.to(device)\n",
        "#         y_batch_t = y_batch.to(device)\n",
        "#         a_mask = (x_batch>0).to(device)\n",
        "#         y_pred = model(x_batch_t, attention_mask=a_mask, labels=None)\n",
        "#         loss =  F.binary_cross_entropy_with_logits(y_pred, y_batch_t)\n",
        "#         print(loss.item())\n",
        "#     else:\n",
        "#         continue\n",
        "        \n",
        "# del model, optimizer, y_pred, x_batch, y_batch, x_batch_t, y_batch_t, tq1, a_mask, loss\n",
        "# torch.cuda.empty_cache()\n",
        "# gc.collect()\n",
        "# print(round(torch.cuda.memory_allocated(device)/(1024**3),1), round(torch.cuda.memory_cached(device)/(1024**3),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "507fbddf-f7aa-4b99-9b3a-c8cb6b42e86b",
        "_cell_guid": "2e46785e-4428-4cd0-ad33-9203874397a7",
        "trusted": true,
        "scrolled": true,
        "id": "BtOHLfhf6SB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tq = tqdm(range(epochs))\n",
        "\n",
        "for epoch in tq:\n",
        "    avg_loss = 0.\n",
        "    avg_accuracy = 0.\n",
        "    lossf = None\n",
        "    optimizer.zero_grad()\n",
        "    tq1 = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    \n",
        "    for i, (x_batch, y_batch) in tq1:\n",
        "        x_batch_t = x_batch.to(device)\n",
        "        y_batch_t = y_batch.to(device)\n",
        "        a_mask = (x_batch>0).to(device)\n",
        "        y_pred = model(x_batch_t, attention_mask=a_mask, labels=None)\n",
        "        loss =  F.binary_cross_entropy_with_logits(y_pred, y_batch_t)\n",
        "        print(i)\n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "            scaled_loss.backward()\n",
        "        if (i+1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        if lossf:\n",
        "            lossf = 0.98*lossf+0.02*loss.item()\n",
        "        else:\n",
        "            lossf = loss.item()\n",
        "        tq1.set_postfix(loss = lossf)\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float)).item()/len(train_loader)\n",
        "    tq.set_postfix(avg_loss=avg_loss, avg_accuracy=avg_accuracy)\n",
        "    \n",
        "# checkpoint_model_file = 'bert_pytorch_checkpoint.bin'\n",
        "# torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, checkpoint_model_file)\n",
        "\n",
        "output_model_file = \"bert_pytorch.bin\"\n",
        "torch.save(model.state_dict(), output_model_file)\n",
        "\n",
        "del model, optimizer, x_batch, y_batch, y_pred, tq, tq1, loss, scaled_loss, a_mask, x_batch_t, y_batch_t\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(round(torch.cuda.memory_allocated(device)/(1024**3),1), round(torch.cuda.memory_cached(device)/(1024**3),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9e149f92-59a2-4b80-bdf3-eef6c2027820",
        "_cell_guid": "8504508d-c68b-4a20-876b-5024027f57f3",
        "trusted": true,
        "id": "EBefOCIk6SDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
        "print(test_df.shape)\n",
        "\n",
        "test_df['comment_text'] = test_df['comment_text'].astype(str).fillna('DUMMY_VALUE')\n",
        "\n",
        "X_test = convert_lines(test_df[\"comment_text\"], max_seq_length, tokenizer)\n",
        "\n",
        "test = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4447447d-6bc3-448c-8d07-48fb6d843f29",
        "_cell_guid": "70ea9845-d51a-4a7b-ba88-ebffe8b53c4e",
        "trusted": true,
        "scrolled": true,
        "id": "bLA5-0ft6SDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification(bert_config, num_labels=len(y_columns))\n",
        "# model.load_state_dict(torch.load(output_model_file))\n",
        "model.load_state_dict(torch.load('../input/toxic-bert-plain-vanila/bert_pytorch.bin'))\n",
        "model.to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()\n",
        "\n",
        "test_preds = np.zeros((len(X_test)))\n",
        "\n",
        "for i, (x_batch, ) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    test_preds[i*batch_size:(i+1)*batch_size] = pred[:,0].detach().cpu().squeeze().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4ff5b457-effb-4ba5-a642-cc8fa72482fe",
        "_cell_guid": "a9e0a262-b9a8-43b9-9785-c50b0c245127",
        "trusted": true,
        "id": "_Vwh1_Df6SDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = torch.sigmoid(torch.tensor(test_preds)).numpy()\n",
        "print(test_preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0e68f401-64b3-43d1-913b-52bff5e609e0",
        "_cell_guid": "50a626db-f30b-4c0c-89c9-3b991b9430e7",
        "trusted": true,
        "id": "DqG1Ioqy6SEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame.from_dict({'id': test_df['id'], 'prediction': test_preds})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}